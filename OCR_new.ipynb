{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBL0HtQHrmOyV8uHVvJlfG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlvssyaswanth/colab-files/blob/main/OCR_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u52GZj966ATd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch torchvision torchaudio pillow opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "urYf2yPk6FDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import glob\n",
        "import shutil"
      ],
      "metadata": {
        "id": "z0ziije26J-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = \"/content/drive/MyDrive/OCR_Dataset\"  # Update this path\n",
        "extract_path = \"/content/extracted_OCR_Dataset/\"  # Temporary extraction folder\n",
        "output_text_file = \"/content/ocr_results.txt\""
      ],
      "metadata": {
        "id": "2XCTWtdh6Mun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "zip_files = [f for f in os.listdir(dataset_folder) if f.endswith(\".zip\")]\n",
        "\n",
        "for zip_file in zip_files:\n",
        "    zip_path = os.path.join(dataset_folder, zip_file)\n",
        "    print(f\" Extracting: {zip_file}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\" All ZIP files extracted to: {extract_path}\")"
      ],
      "metadata": {
        "id": "zzcNkezo6UY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find All Images (Including Subfolders)\n",
        "image_files = glob.glob(os.path.join(extract_path, \"**\", \"*.[jp][pn]g\"), recursive=True)\n",
        "\n",
        "print(f\"Found {len(image_files)} images in dataset.\")\n",
        "print(\" Example image paths:\", image_files[:5])\n",
        "\n",
        "if not image_files:\n",
        "    raise RuntimeError(\" No images found! Check dataset structure.\")"
      ],
      "metadata": {
        "id": "H05A5qSM6WuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Images for OCR\n",
        "def preprocess_image(image_path):\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\" Could not read image: {image_path}\")\n",
        "            return None\n",
        "\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "        processed = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                          cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "        # Resize for better OCR accuracy\n",
        "        processed = cv2.resize(processed, (1024, 1024), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        return processed\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing {image_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ougV_oo86Yv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load TrOCR Model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\").to(device)"
      ],
      "metadata": {
        "id": "HNGPDKuD6at4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform OCR with TrOCR for First 10,000 Images\n",
        "ocr_results = {}\n",
        "\n",
        "#  Limit processing to 10,000 images\n",
        "max_images = min(10000, len(image_files))\n",
        "\n",
        "for i, img_path in enumerate(image_files[:max_images]):  # Process first 10,000 images\n",
        "    print(f\"üîç Processing {i+1}/{max_images}: {img_path}\")\n",
        "\n",
        "    # Preprocess the image\n",
        "    processed_img = preprocess_image(img_path)\n",
        "    if processed_img is None:\n",
        "        continue\n",
        "\n",
        "    # Convert OpenCV image to PIL format\n",
        "    pil_image = Image.fromarray(processed_img).convert(\"RGB\")\n",
        "\n",
        "    #  Prepare image for TrOCR\n",
        "    pixel_values = processor(pil_image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "\n",
        "    #  Perform OCR\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(pixel_values)\n",
        "        extracted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    print(f\"üìÑ Extracted Text:\\n{extracted_text}\")\n",
        "\n",
        "    #  Store result\n",
        "    ocr_results[img_path] = extracted_text\n",
        "\n",
        "print(f\" Finished processing {max_images} images.\")"
      ],
      "metadata": {
        "id": "czNcmdjp6dS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "\n",
        "import Levenshtein\n",
        "\n",
        "# ‚úÖ Step 1: Load Ground Truth Data\n",
        "# You should have a dictionary {image_path: actual_text} for comparison\n",
        "ground_truth = {\n",
        "    \"/content/extracted_OCR_Dataset/image1.jpg\": \"This is the correct text\",\n",
        "    \"/content/extracted_OCR_Dataset/image2.jpg\": \"Another example of OCR\",\n",
        "    # Add more image-to-text mappings\n",
        "}\n",
        "\n",
        "# ‚úÖ Step 2: Define Accuracy Calculation Function\n",
        "def calculate_accuracy(ocr_results, ground_truth):\n",
        "    total_images = len(ground_truth)\n",
        "    total_cer = 0  # Character Error Rate\n",
        "    total_wer = 0  # Word Error Rate\n",
        "\n",
        "    for img_path, actual_text in ground_truth.items():\n",
        "        if img_path in ocr_results:\n",
        "            predicted_text = ocr_results[img_path]\n",
        "\n",
        "            # ‚úÖ Compute Character Error Rate (CER)\n",
        "            cer = Levenshtein.distance(actual_text, predicted_text) / max(1, len(actual_text))\n",
        "            total_cer += cer\n",
        "\n",
        "            # ‚úÖ Compute Word Error Rate (WER)\n",
        "            actual_words = actual_text.split()\n",
        "            predicted_words = predicted_text.split()\n",
        "            wer = Levenshtein.distance(\" \".join(actual_words), \" \".join(predicted_words)) / max(1, len(actual_words))\n",
        "            total_wer += wer\n",
        "\n",
        "    # ‚úÖ Compute Final Accuracy Scores\n",
        "    avg_cer = (1 - (total_cer / total_images)) * 100\n",
        "    avg_wer = (1 - (total_wer / total_images)) * 100\n",
        "\n",
        "    print(f\"‚úÖ OCR Accuracy Results:\")\n",
        "    print(f\"üéØ Character-Level Accuracy: {avg_cer:.2f}%\")\n",
        "    print(f\"üéØ Word-Level Accuracy: {avg_wer:.2f}%\")\n",
        "\n",
        "# ‚úÖ Step 3: Run Accuracy Calculation\n",
        "calculate_accuracy(ocr_results, ground_truth)"
      ],
      "metadata": {
        "id": "-ADlm7xi6f7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 10: Save OCR Results to a Text File\n",
        "with open(output_text_file, \"w\") as f:\n",
        "    for img, text in ocr_results.items():\n",
        "        f.write(f\"Image: {img}\\nExtracted Text:\\n{text}\\n\")\n",
        "        f.write(\"=\"*50 + \"\\n\")\n",
        "\n",
        "print(f\"‚úÖ OCR results saved to: {output_text_file}\")\n",
        "\n",
        "# ‚úÖ Step 11: Download OCR Results\n",
        "from google.colab import files\n",
        "files.download(output_text_file)"
      ],
      "metadata": {
        "id": "3eRecuXZ6i9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 12: Save OCR Results to Google Drive\n",
        "drive_save_path = \"/content/drive/MyDrive/OCR_Results.txt\"\n",
        "shutil.move(output_text_file, drive_save_path)\n",
        "print(f\"‚úÖ OCR results saved to Google Drive at: {drive_save_path}\")"
      ],
      "metadata": {
        "id": "bFF8CH3K6nYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Define save path\n",
        "model_save_path = \"/content/trained_trocr_model\"\n",
        "\n",
        "# ‚úÖ Save the trained model and processor\n",
        "model.save_pretrained(model_save_path)\n",
        "processor.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved at: {model_save_path}\")"
      ],
      "metadata": {
        "id": "VvQv1YvJ6qJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# ‚úÖ Compress the model folder into a ZIP file\n",
        "shutil.make_archive(\"trocr_model\", 'zip', model_save_path)\n",
        "\n",
        "# ‚úÖ Download the ZIP file\n",
        "files.download(\"trocr_model.zip\")"
      ],
      "metadata": {
        "id": "DmMmBp1j6sCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_save_path = \"/content/drive/MyDrive/trained_trocr_model\"\n",
        "\n",
        "# ‚úÖ Move model to Google Drive\n",
        "shutil.move(model_save_path, drive_save_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to Google Drive at: {drive_save_path}\")"
      ],
      "metadata": {
        "id": "HZwdVXVo6t7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}